## C103F Spring 2019: The GD-Scene
<img src="56252806_317928325473583_7763946393101664256_n.jpg" width="800" />
From left to right: Sue Anne Davis, Jonathan Ham, Lina Ly, Shailen Patel 

AI plays a huge role in society by aiding decision making and risk assessment in numerous areas of life. From using COMPAS to determine the likelihood of a criminal’s reoffense to using ADM (Automated Decision-Making) to help decide whether someone should be able to obtain a mortgage, society is becoming reliant on AI for decision making.

The advantages of AI can be beneficial in which ADM systems can increase fairness (Inspecting Algorithms for Bias). By referring to ADM systems, decisions could be more “fair” in which decisions made by individuals could be more biased depending on their implicit biases and environmental factors. Disadvantages of AI include allocative harm, or when the system denies an individual or group a certain opportunity or resource, and representational harm, in which systems reinforce a certain result for certain groups (AI Professor Details Real-World Dangers of Algorithm Bias).  These advantages outweigh disadvantages when either the model is less biased than the alternative decision making process, or when the model is not making judgements on people. 

Solutions that have been proposed include collecting more testing data from underrepresented groups, increasing bias testing by third-parties during the development cycle, and expanding the workforce of those who work on AI algorithms and models.  All of these solutions could help solve the problem, but the root of the issue is using demographic data to predict an individual’s outcomes, which is inherently discriminatory. Thus, whenever demographic data is utilized (even if it increases the accuracy of the model), the problem will always exist. 

As humans, it is ethical eliminate our biases, as per the duty-based framework in which we should treat people equally. As computer scientists, we have a greater ethical need for making sure these biases are suppressed, as through the Consequentialist framework, where our biases could create models that harm more people than one person would ever interact with. Even if we are not in the field of AI, we still understand how AI works, and it is therefore still our responsibility as experts to make sure that end-users understand the inherent drawbacks and consequences. 

In a development life cycle, ethical dilemmas could be brushed off in favor of higher accuracy, for example. As a result, ethical fading and incrementalism is dependent on the work environment and product expectations. If the work is done in a closed environment without much external input, then the ethical mindset of the individual will simply amplify itself until it is an extreme. Because of our susceptibility, it is important that we provide ourselves with differing viewpoints.


## C103F Spring 2019: The GD-Scene
<img src="56252806_317928325473583_7763946393101664256_n.jpg" width="800" />
From left to right: Sue Anne Davis, Jonathan Ham, Lina Ly, Shailen Patel 

The effects of hacktivism on society is helpful when there is a fight for free unrestricted access of information for individuals. Hacktivism can be used to counter censorship that many individuals around the world face, such as Tunisians. Hacktivism can be beneficial to society when fighting for the civil liberties of people, but can also just create chaos (marketplace.org).

Hacktivist groups often champion their effects on individuals. For those who are unable to access information, or who only have censored information, individuals rely on hacktivists to be educated and aware of their surroundings. Additionally, individuals that live in an environment where they are unable to voice their concerns benefit as they are given a platform to raise awareness and incite change. However, hacktivists get to choose their targets, often somewhat randomly and vengefully, which can harm innocent individuals with no recourse. 

Hacktivism is ethical when it can be used to spark social change and allow access to free, unrestricted information for those unable to obtain it otherwise.  However, hacktivism can also be viewed as unethical, as cyber attacks are illegal. Besides the concern of legality, hacktivism can also be socially harmful. In the Ashley Madison case, hackers leaked the information of users which probably ruined the relationships of many people. 

A consequentialist framework could be used to evaluate whether the action of a hacktivist group was ethical or beneficial, however, a virtue ethical framework can consider the history of the group and help determine whether the group had good intentions. Additionally, it is hard to determine the full consequences of an action because actions of hacktivist groups typically have far reaching effects. While some might see it as good that an unethical business was attacked by a hacktivist group, that business would see the attack as decidedly bad. Because of this duality, ethicality and effects can only be evaluated accurately when looking at the action from each side individually.

https://www.marketplace.org/2017/04/28/tech/founder-hacker-group-lulzsec-explains-chaos-hacktivism


## C103F Spring 2019: Group 18
<img src="56252806_317928325473583_7763946393101664256_n.jpg" width="800" />
From left to right: Sue Anne Davis, Jonathan Ham, Lina Ly, Shailen Patel 


Allowing companies insight into our daily browsing habits and lifestyle choices gives us benefits previously never imagined, such as coupons to our favorite restaurants and real-time low traffic routes. However, individuals may vary on what they are willing to share, which could be impacted by trust in the company, their own personal paranoias, and the company’s intent when using the data. 

This trade affects society mainly by creating a distrust between businesses that collect data and the users who generate the data. Most users are poorly informed about how their data is collected and to what degree their data is linked to them, so when they hear that a company is tracking their data, their first reactions are fear and anger. However, for the portion of people who are aware and content with how their data is used, then it can provide a possible efficiency and quality boost. Despite this, the data trade can have major negative effects through the targeted spread of misinformation.

The tech industry ‘s responsibilities can be understood from a consequentialist ethical framework since they have to prevent it from getting it into the “wrong hands”. If it were to get in the wrong hands, situations as impactful as influencing the political election can occur. Companies also have the responsibility to be transparent with their users. As a result, executives of these tech companies need to have more of these ethical discussions amongst themselves and with third parties. This will help ensure their users aren’t forced to be put into potentially compromising situations by sharing their data with the company.

Informed consent is when the company is transparent with the user about what data they are collecting, who is able to access their data, and what that data might be used for. 

Both the user and the company that is retaining the personal data own the data as the user entrusts the company with their information. However, the company should not be able to provide that data to third parties without the user’s permission.
